# -*- coding: utf-8 -*-
"""SNA1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bcs13JKDXcdMVNYvGp-aup_38GXWT7rL
"""

import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from networkx.algorithms.community import modularity

# ----------------------------
# STEP 1: CREATE OR LOAD DATA
# ----------------------------

# Example simulated Instagram engagement data
data = pd.DataFrame({
    "User_A": ["U1", "U1", "U2", "U3", "U3", "U4"],
    "User_B": ["U2", "U3", "U3", "U4", "U1", "U3"],
    "Likes": [5, 2, 3, 4, 1, 3],
    "Comments": [1, 0, 2, 1, 1, 0],
    "Shares": [0, 0, 1, 0, 0, 0]
})

# Weighted engagement score (comments weighted more)
data["Engagement_Score"] = data["Likes"] + 2*data["Comments"] + 3*data["Shares"]
print("Engagement data:\n", data)

# ----------------------------
# STEP 2: BUILD INTERACTION GRAPH
# ----------------------------
G = nx.Graph()
for _, row in data.iterrows():
    G.add_edge(row["User_A"], row["User_B"], weight=row["Engagement_Score"])

print("\nGraph nodes:", G.nodes())
print("Graph edges with weights:", G.edges(data=True))

# Quick visualization
plt.figure(figsize=(5,4))
pos = nx.spring_layout(G)
nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=800, font_weight='bold')
edge_labels = nx.get_edge_attributes(G, 'weight')
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)
plt.title("Engagement Graph")
plt.show()

# ----------------------------
# STEP 3: BUILD MATRICES (Adjacency, Degree, Laplacian)
# ----------------------------
A = nx.to_numpy_array(G, weight="weight")
nodes = list(G.nodes())
D = np.diag(A.sum(axis=1))
L = D - A

print("\nAdjacency Matrix:\n", A)
print("\nDegree Matrix:\n", D)
print("\nGraph Laplacian (L):\n", L)

# ----------------------------
# STEP 4: SPECTRAL EMBEDDING
# ----------------------------
eigvals, eigvecs = np.linalg.eigh(L)
idx = np.argsort(eigvals)
eigvals, eigvecs = eigvals[idx], eigvecs[:, idx]

print("\nEigenvalues (sorted):", eigvals)

# Choose embedding dimension k=2 (skip the first eigenvector associated with eigenvalue 0)
k = 2
embedding = eigvecs[:, 1:k+1]
print("\nSpectral embedding (2D coordinates):\n", embedding)

# ----------------------------
# STEP 5: KMEANS CLUSTERING
# ----------------------------
kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
labels = kmeans.fit_predict(embedding)
print("\nCluster assignments:")
for user, cluster in zip(nodes, labels):
    print(f"User {user} -> Cluster {cluster}")

# Plot embedding with clusters
plt.figure(figsize=(6,5))
plt.scatter(embedding[:,0], embedding[:,1], c=labels, cmap='rainbow', s=200)
for i, user in enumerate(nodes):
    plt.text(embedding[i,0], embedding[i,1], user, fontsize=12, ha='center', va='center', color='black')
plt.title("Spectral Embedding with KMeans Clusters")
plt.xlabel("Eigenvector 2")
plt.ylabel("Eigenvector 3")
plt.grid()
plt.show()

# ----------------------------
# STEP 6: INFLUENCER RANKING
# ----------------------------
deg_centrality = nx.degree_centrality(G)
bet_centrality = nx.betweenness_centrality(G, weight="weight")
eig_centrality = nx.eigenvector_centrality_numpy(G, weight="weight")

centrality_df = pd.DataFrame({
    "User": nodes,
    "Degree_Centrality": [deg_centrality[u] for u in nodes],
    "Betweenness": [bet_centrality[u] for u in nodes],
    "Eigenvector_Centrality": [eig_centrality[u] for u in nodes],
    "Cluster": labels
}).sort_values(by="Eigenvector_Centrality", ascending=False)

print("\nInfluencer Ranking Table (by Eigenvector Centrality):\n", centrality_df)

# ----------------------------
# STEP 7: EVALUATION METRICS
# ----------------------------
sil_score = silhouette_score(embedding, labels)
print("\nSilhouette Score:", sil_score)

communities = [set(np.array(nodes)[labels == c]) for c in set(labels)]
mod_score = modularity(G, communities)
print("Modularity:", mod_score)